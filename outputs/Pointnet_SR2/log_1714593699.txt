Arguments: Namespace(local_rank=None, use_sync_bn=False, use_amp=False, script_mode='train', config='cfgs/pn2-msg.yaml', seed=1, epochs=250, batch_size=32, num_workers=4, resume='/content/drive/MyDrive/SemNov_AML_DAAI_23-24/outputs/Pointnet_SR2/models/model_last.pth', apply_fix_cellphone=True, data_root='./3D_OS_release_data', checkpoints_dir='outputs', exp_name='Pointnet_SR2', eval_step=5, save_step=10, ckpt_path=None, src='SR2', sonn_split='main_split', sonn_h5_name='objectdataset.h5', augm_set='rw', grad_norm_clip=-1, num_points=1024, num_points_test=2048, wandb_name=None, wandb_group='md-2-sonn-augmCorr', wandb_proj='AML_DAAI_proj23_24_Pointnet_SR2', loss='CE', cs=False, cs_gan_lr=0.0002, cs_beta=0.1, save_feats=None, corruption=None, tar1='none', tar2='none', log_dir='outputs/Pointnet_SR2', tb_dir='outputs/Pointnet_SR2/tb-logs', models_dir='outputs/Pointnet_SR2/models', backup_dir='outputs/Pointnet_SR2/backup-code')
Config: {'optimizer': {'type': 'adam', 'skip_wd': [], 'weight_decay': 0.0001, 'kwargs': {'lr': 0.001}}, 'scheduler': {'type': 'CosLR', 'kwargs': {'t_initial': 250, 'cycle_limit': 1, 'lr_min': 1e-05}}, 'model': {'ENCO_NAME': 'pn2-msg', 'dropout': 0.5, 'cla_input_dim': 1024, 'act': 'relu'}}
World size: 1

SR2 train synset: {'bed': 0, 'toilet': 1, 'desk': 2, 'monitor': 3, 'table': 2}
Source: SR2
Num training classes: 4
Model: 
Classifier(
  (enco): Pointnet2_MSG_Y(
    (sa1): PointNetSetAbstractionMsg(
      (conv_blocks): ModuleList(
        (0): ModuleList(
          (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ModuleList(
          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): ModuleList(
          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bn_blocks): ModuleList(
        (0): ModuleList(
          (0-1): 2 x BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): ModuleList(
          (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): ModuleList(
          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (sa2): PointNetSetAbstractionMsg(
      (conv_blocks): ModuleList(
        (0): ModuleList(
          (0): Conv2d(323, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (1-2): 2 x ModuleList(
          (0): Conv2d(323, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bn_blocks): ModuleList(
        (0): ModuleList(
          (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1-2): 2 x ModuleList(
          (0-1): 2 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (sa3): PointNetSetAbstraction(
      (mlp_convs): ModuleList(
        (0): Conv2d(643, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (mlp_bns): ModuleList(
        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (penultimate): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=False)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=512, out_features=256, bias=False)
  )
  (head): Sequential(
    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=256, out_features=4, bias=True)
  )
)

param count: 
1.7373 M
Loss: CE

Restart training from checkpoint /content/drive/MyDrive/SemNov_AML_DAAI_23-24/outputs/Pointnet_SR2/models/model_last.pth
it: [10/59-196/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0021, lr: 0.000124, BT: 1.04, DT: 0.00
it: [20/59-196/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0018, lr: 0.000124, BT: 1.09, DT: 0.01
it: [30/59-196/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0016, lr: 0.000124, BT: 1.15, DT: 0.01
it: [40/59-196/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0024, lr: 0.000124, BT: 1.05, DT: 0.00
it: [50/59-196/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0030, lr: 0.000124, BT: 1.05, DT: 0.00
Train [196/250]	rank: [1/1], Loss: 0.0027, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.28, DT: 0.01,  epoch time: 75.62
it: [10/59-197/250], rank: [1/1], Loss: 0.0030, Loss avg: 0.0012, lr: 0.000120, BT: 1.15, DT: 0.00
it: [20/59-197/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0009, lr: 0.000120, BT: 1.04, DT: 0.00
it: [30/59-197/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0009, lr: 0.000120, BT: 1.06, DT: 0.00
it: [40/59-197/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0011, lr: 0.000120, BT: 1.05, DT: 0.00
it: [50/59-197/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0011, lr: 0.000120, BT: 1.07, DT: 0.00
Train [197/250]	rank: [1/1], Loss: 0.0010, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.08, DT: 0.01,  epoch time: 63.97
it: [10/59-198/250], rank: [1/1], Loss: 0.0250, Loss avg: 0.0030, lr: 0.000116, BT: 1.12, DT: 0.01
it: [20/59-198/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0036, lr: 0.000116, BT: 1.07, DT: 0.00
it: [30/59-198/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0025, lr: 0.000116, BT: 1.06, DT: 0.00
it: [40/59-198/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0021, lr: 0.000116, BT: 1.06, DT: 0.00
it: [50/59-198/250], rank: [1/1], Loss: 0.0028, Loss avg: 0.0019, lr: 0.000116, BT: 1.18, DT: 0.00
Train [198/250]	rank: [1/1], Loss: 0.0034, Acc: 0.9984, Bal Acc: 0.9986, BT: 1.11, DT: 0.01,  epoch time: 65.27
it: [10/59-199/250], rank: [1/1], Loss: 0.0022, Loss avg: 0.0046, lr: 0.000112, BT: 1.08, DT: 0.00
it: [20/59-199/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0063, lr: 0.000112, BT: 1.08, DT: 0.00
it: [30/59-199/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0070, lr: 0.000112, BT: 1.07, DT: 0.00
it: [40/59-199/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0054, lr: 0.000112, BT: 1.16, DT: 0.01
it: [50/59-199/250], rank: [1/1], Loss: 0.0180, Loss avg: 0.0051, lr: 0.000112, BT: 1.19, DT: 0.01
Train [199/250]	rank: [1/1], Loss: 0.0045, Acc: 0.9979, Bal Acc: 0.9982, BT: 1.11, DT: 0.01,  epoch time: 65.85
it: [10/59-200/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0023, lr: 0.000108, BT: 1.06, DT: 0.00
it: [20/59-200/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0020, lr: 0.000108, BT: 1.07, DT: 0.00
it: [30/59-200/250], rank: [1/1], Loss: 0.0017, Loss avg: 0.0021, lr: 0.000108, BT: 1.08, DT: 0.00
it: [40/59-200/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0017, lr: 0.000108, BT: 1.17, DT: 0.00
it: [50/59-200/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0017, lr: 0.000108, BT: 1.08, DT: 0.00
Train [200/250]	rank: [1/1], Loss: 0.0028, Acc: 0.9995, Bal Acc: 0.9995, BT: 1.11, DT: 0.01,  epoch time: 65.49
Test [200/250]	Acc: 0.9958, Bal Acc: 0.9950
it: [10/59-201/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0007, lr: 0.000105, BT: 1.23, DT: 0.00
it: [20/59-201/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0016, lr: 0.000105, BT: 1.17, DT: 0.00
it: [30/59-201/250], rank: [1/1], Loss: 0.0012, Loss avg: 0.0013, lr: 0.000105, BT: 1.07, DT: 0.00
it: [40/59-201/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0031, lr: 0.000105, BT: 1.08, DT: 0.00
it: [50/59-201/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0026, lr: 0.000105, BT: 1.07, DT: 0.00
Train [201/250]	rank: [1/1], Loss: 0.0023, Acc: 0.9989, Bal Acc: 0.9988, BT: 1.11, DT: 0.01,  epoch time: 65.78
it: [10/59-202/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0010, lr: 0.000101, BT: 1.07, DT: 0.00
it: [20/59-202/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0008, lr: 0.000101, BT: 1.07, DT: 0.00
it: [30/59-202/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0009, lr: 0.000101, BT: 1.07, DT: 0.00
it: [40/59-202/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0016, lr: 0.000101, BT: 1.08, DT: 0.00
it: [50/59-202/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0014, lr: 0.000101, BT: 1.24, DT: 0.01
Train [202/250]	rank: [1/1], Loss: 0.0023, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.11, DT: 0.01,  epoch time: 65.66
it: [10/59-203/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0118, lr: 0.000097, BT: 1.07, DT: 0.00
it: [20/59-203/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0064, lr: 0.000097, BT: 1.07, DT: 0.00
it: [30/59-203/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0045, lr: 0.000097, BT: 1.07, DT: 0.00
it: [40/59-203/250], rank: [1/1], Loss: 0.0018, Loss avg: 0.0036, lr: 0.000097, BT: 1.08, DT: 0.00
it: [50/59-203/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0039, lr: 0.000097, BT: 1.17, DT: 0.00
Train [203/250]	rank: [1/1], Loss: 0.0044, Acc: 0.9989, Bal Acc: 0.9991, BT: 1.11, DT: 0.01,  epoch time: 65.61
it: [10/59-204/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0006, lr: 0.000094, BT: 1.08, DT: 0.00
it: [20/59-204/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0019, lr: 0.000094, BT: 1.09, DT: 0.00
it: [30/59-204/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0018, lr: 0.000094, BT: 1.07, DT: 0.00
it: [40/59-204/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0016, lr: 0.000094, BT: 1.15, DT: 0.01
it: [50/59-204/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0016, lr: 0.000094, BT: 1.08, DT: 0.00
Train [204/250]	rank: [1/1], Loss: 0.0026, Acc: 0.9989, Bal Acc: 0.9988, BT: 1.11, DT: 0.01,  epoch time: 65.66
it: [10/59-205/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0005, lr: 0.000090, BT: 1.08, DT: 0.00
it: [20/59-205/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0011, lr: 0.000090, BT: 1.07, DT: 0.00
it: [30/59-205/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0012, lr: 0.000090, BT: 1.20, DT: 0.01
it: [40/59-205/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0012, lr: 0.000090, BT: 1.20, DT: 0.01
it: [50/59-205/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0011, lr: 0.000090, BT: 1.09, DT: 0.01
Train [205/250]	rank: [1/1], Loss: 0.0023, Acc: 0.9995, Bal Acc: 0.9993, BT: 1.12, DT: 0.01,  epoch time: 66.00
Test [205/250]	Acc: 0.9917, Bal Acc: 0.9911
it: [10/59-206/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0007, lr: 0.000087, BT: 1.20, DT: 0.01
it: [20/59-206/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0011, lr: 0.000087, BT: 1.08, DT: 0.00
it: [30/59-206/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0013, lr: 0.000087, BT: 1.09, DT: 0.00
it: [40/59-206/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0044, lr: 0.000087, BT: 1.07, DT: 0.00
it: [50/59-206/250], rank: [1/1], Loss: 0.0049, Loss avg: 0.0037, lr: 0.000087, BT: 1.07, DT: 0.00
Train [206/250]	rank: [1/1], Loss: 0.0033, Acc: 0.9989, Bal Acc: 0.9990, BT: 1.11, DT: 0.01,  epoch time: 65.47
it: [10/59-207/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0007, lr: 0.000084, BT: 1.09, DT: 0.00
it: [20/59-207/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0012, lr: 0.000084, BT: 1.11, DT: 0.00
it: [30/59-207/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0016, lr: 0.000084, BT: 1.08, DT: 0.00
it: [40/59-207/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0016, lr: 0.000084, BT: 1.07, DT: 0.00
it: [50/59-207/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0014, lr: 0.000084, BT: 1.08, DT: 0.00
Train [207/250]	rank: [1/1], Loss: 0.0016, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.11, DT: 0.01,  epoch time: 65.66
it: [10/59-208/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0008, lr: 0.000081, BT: 1.07, DT: 0.00
it: [20/59-208/250], rank: [1/1], Loss: 0.0028, Loss avg: 0.0024, lr: 0.000081, BT: 1.08, DT: 0.00
it: [30/59-208/250], rank: [1/1], Loss: 0.0030, Loss avg: 0.0019, lr: 0.000081, BT: 1.08, DT: 0.00
it: [40/59-208/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0016, lr: 0.000081, BT: 1.19, DT: 0.00
it: [50/59-208/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0014, lr: 0.000081, BT: 1.16, DT: 0.00
Train [208/250]	rank: [1/1], Loss: 0.0018, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.12, DT: 0.01,  epoch time: 66.12
it: [10/59-209/250], rank: [1/1], Loss: 0.0980, Loss avg: 0.0105, lr: 0.000077, BT: 1.11, DT: 0.00
it: [20/59-209/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0056, lr: 0.000077, BT: 1.06, DT: 0.00
it: [30/59-209/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0040, lr: 0.000077, BT: 1.18, DT: 0.00
it: [40/59-209/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0031, lr: 0.000077, BT: 1.16, DT: 0.00
it: [50/59-209/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0031, lr: 0.000077, BT: 1.08, DT: 0.00
Train [209/250]	rank: [1/1], Loss: 0.0028, Acc: 0.9989, Bal Acc: 0.9985, BT: 1.10, DT: 0.01,  epoch time: 65.24
it: [10/59-210/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0011, lr: 0.000074, BT: 1.07, DT: 0.00
it: [20/59-210/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0036, lr: 0.000074, BT: 1.09, DT: 0.00
it: [30/59-210/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0030, lr: 0.000074, BT: 1.16, DT: 0.00
it: [40/59-210/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0026, lr: 0.000074, BT: 1.07, DT: 0.00
it: [50/59-210/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0027, lr: 0.000074, BT: 1.08, DT: 0.00
Train [210/250]	rank: [1/1], Loss: 0.0024, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.11, DT: 0.01,  epoch time: 65.51
Test [210/250]	Acc: 0.9958, Bal Acc: 0.9949
it: [10/59-211/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0007, lr: 0.000071, BT: 1.08, DT: 0.00
it: [20/59-211/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0006, lr: 0.000071, BT: 1.10, DT: 0.00
it: [30/59-211/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0023, lr: 0.000071, BT: 1.08, DT: 0.00
it: [40/59-211/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0021, lr: 0.000071, BT: 1.08, DT: 0.00
it: [50/59-211/250], rank: [1/1], Loss: 0.0012, Loss avg: 0.0021, lr: 0.000071, BT: 1.16, DT: 0.01
Train [211/250]	rank: [1/1], Loss: 0.0025, Acc: 0.9989, Bal Acc: 0.9990, BT: 1.12, DT: 0.01,  epoch time: 66.19
it: [10/59-212/250], rank: [1/1], Loss: 0.0039, Loss avg: 0.0074, lr: 0.000068, BT: 1.09, DT: 0.00
it: [20/59-212/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0051, lr: 0.000068, BT: 1.08, DT: 0.00
it: [30/59-212/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0047, lr: 0.000068, BT: 1.07, DT: 0.00
it: [40/59-212/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0046, lr: 0.000068, BT: 1.07, DT: 0.00
it: [50/59-212/250], rank: [1/1], Loss: 0.0035, Loss avg: 0.0041, lr: 0.000068, BT: 1.17, DT: 0.00
Train [212/250]	rank: [1/1], Loss: 0.0037, Acc: 0.9995, Bal Acc: 0.9995, BT: 1.12, DT: 0.01,  epoch time: 66.27
it: [10/59-213/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0005, lr: 0.000065, BT: 1.08, DT: 0.00
it: [20/59-213/250], rank: [1/1], Loss: 0.0028, Loss avg: 0.0007, lr: 0.000065, BT: 1.07, DT: 0.00
it: [30/59-213/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0010, lr: 0.000065, BT: 1.08, DT: 0.00
it: [40/59-213/250], rank: [1/1], Loss: 0.0032, Loss avg: 0.0011, lr: 0.000065, BT: 1.16, DT: 0.00
it: [50/59-213/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0020, lr: 0.000065, BT: 1.07, DT: 0.00
Train [213/250]	rank: [1/1], Loss: 0.0018, Acc: 0.9995, Bal Acc: 0.9995, BT: 1.10, DT: 0.01,  epoch time: 65.17
it: [10/59-214/250], rank: [1/1], Loss: 0.0059, Loss avg: 0.0015, lr: 0.000063, BT: 1.08, DT: 0.01
it: [20/59-214/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0009, lr: 0.000063, BT: 1.08, DT: 0.00
it: [30/59-214/250], rank: [1/1], Loss: 0.0135, Loss avg: 0.0041, lr: 0.000063, BT: 1.21, DT: 0.01
it: [40/59-214/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0032, lr: 0.000063, BT: 1.07, DT: 0.00
it: [50/59-214/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0058, lr: 0.000063, BT: 1.09, DT: 0.00
Train [214/250]	rank: [1/1], Loss: 0.0052, Acc: 0.9989, Bal Acc: 0.9990, BT: 1.11, DT: 0.01,  epoch time: 65.76
it: [10/59-215/250], rank: [1/1], Loss: 0.0031, Loss avg: 0.0010, lr: 0.000060, BT: 1.08, DT: 0.00
it: [20/59-215/250], rank: [1/1], Loss: 0.0059, Loss avg: 0.0080, lr: 0.000060, BT: 1.18, DT: 0.00
it: [30/59-215/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0069, lr: 0.000060, BT: 1.06, DT: 0.00
it: [40/59-215/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0053, lr: 0.000060, BT: 1.07, DT: 0.00
it: [50/59-215/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0046, lr: 0.000060, BT: 1.06, DT: 0.00
Train [215/250]	rank: [1/1], Loss: 0.0040, Acc: 0.9989, Bal Acc: 0.9990, BT: 1.10, DT: 0.01,  epoch time: 65.11
Test [215/250]	Acc: 0.9938, Bal Acc: 0.9948
it: [10/59-216/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0198, lr: 0.000057, BT: 1.07, DT: 0.00
it: [20/59-216/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0102, lr: 0.000057, BT: 1.07, DT: 0.00
it: [30/59-216/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0081, lr: 0.000057, BT: 1.07, DT: 0.00
it: [40/59-216/250], rank: [1/1], Loss: 0.0029, Loss avg: 0.0065, lr: 0.000057, BT: 1.16, DT: 0.00
it: [50/59-216/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0057, lr: 0.000057, BT: 1.17, DT: 0.01
Train [216/250]	rank: [1/1], Loss: 0.0054, Acc: 0.9989, Bal Acc: 0.9991, BT: 1.11, DT: 0.01,  epoch time: 65.33
it: [10/59-217/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0039, lr: 0.000054, BT: 1.08, DT: 0.00
it: [20/59-217/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0078, lr: 0.000054, BT: 1.07, DT: 0.00
it: [30/59-217/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0055, lr: 0.000054, BT: 1.19, DT: 0.01
it: [40/59-217/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0042, lr: 0.000054, BT: 1.07, DT: 0.00
it: [50/59-217/250], rank: [1/1], Loss: 0.0024, Loss avg: 0.0041, lr: 0.000054, BT: 1.07, DT: 0.00
Train [217/250]	rank: [1/1], Loss: 0.0042, Acc: 0.9979, Bal Acc: 0.9980, BT: 1.11, DT: 0.01,  epoch time: 65.65
it: [10/59-218/250], rank: [1/1], Loss: 0.0416, Loss avg: 0.0056, lr: 0.000052, BT: 1.07, DT: 0.00
it: [20/59-218/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0034, lr: 0.000052, BT: 1.17, DT: 0.00
it: [30/59-218/250], rank: [1/1], Loss: 0.0026, Loss avg: 0.0026, lr: 0.000052, BT: 1.09, DT: 0.00
it: [40/59-218/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0028, lr: 0.000052, BT: 1.07, DT: 0.00
it: [50/59-218/250], rank: [1/1], Loss: 0.0023, Loss avg: 0.0024, lr: 0.000052, BT: 1.10, DT: 0.00
Train [218/250]	rank: [1/1], Loss: 0.0022, Acc: 0.9989, Bal Acc: 0.9990, BT: 1.10, DT: 0.01,  epoch time: 65.06
it: [10/59-219/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0009, lr: 0.000049, BT: 1.17, DT: 0.01
it: [20/59-219/250], rank: [1/1], Loss: 0.0000, Loss avg: 0.0016, lr: 0.000049, BT: 1.06, DT: 0.00
it: [30/59-219/250], rank: [1/1], Loss: 0.0017, Loss avg: 0.0013, lr: 0.000049, BT: 1.07, DT: 0.00
it: [40/59-219/250], rank: [1/1], Loss: 0.0027, Loss avg: 0.0012, lr: 0.000049, BT: 1.06, DT: 0.00
it: [50/59-219/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0010, lr: 0.000049, BT: 1.07, DT: 0.00
Train [219/250]	rank: [1/1], Loss: 0.0011, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.10, DT: 0.01,  epoch time: 64.89
it: [10/59-220/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0008, lr: 0.000047, BT: 1.11, DT: 0.00
it: [20/59-220/250], rank: [1/1], Loss: 0.0025, Loss avg: 0.0011, lr: 0.000047, BT: 1.06, DT: 0.00
it: [30/59-220/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0010, lr: 0.000047, BT: 1.07, DT: 0.00
it: [40/59-220/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0009, lr: 0.000047, BT: 1.16, DT: 0.00
it: [50/59-220/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0020, lr: 0.000047, BT: 1.19, DT: 0.01
Train [220/250]	rank: [1/1], Loss: 0.0018, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.11, DT: 0.01,  epoch time: 65.44
Test [220/250]	Acc: 0.9958, Bal Acc: 0.9949
it: [10/59-221/250], rank: [1/1], Loss: 0.0036, Loss avg: 0.0006, lr: 0.000045, BT: 1.06, DT: 0.00
it: [20/59-221/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0006, lr: 0.000045, BT: 1.18, DT: 0.00
it: [30/59-221/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0006, lr: 0.000045, BT: 1.08, DT: 0.00
it: [40/59-221/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0007, lr: 0.000045, BT: 1.09, DT: 0.00
it: [50/59-221/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0028, lr: 0.000045, BT: 1.07, DT: 0.00
Train [221/250]	rank: [1/1], Loss: 0.0044, Acc: 0.9989, Bal Acc: 0.9990, BT: 1.10, DT: 0.01,  epoch time: 65.15
it: [10/59-222/250], rank: [1/1], Loss: 0.0038, Loss avg: 0.0017, lr: 0.000043, BT: 1.15, DT: 0.01
it: [20/59-222/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0018, lr: 0.000043, BT: 1.07, DT: 0.00
it: [30/59-222/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0017, lr: 0.000043, BT: 1.07, DT: 0.00
it: [40/59-222/250], rank: [1/1], Loss: 0.0020, Loss avg: 0.0024, lr: 0.000043, BT: 1.07, DT: 0.00
it: [50/59-222/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0021, lr: 0.000043, BT: 1.08, DT: 0.00
Train [222/250]	rank: [1/1], Loss: 0.0020, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.10, DT: 0.01,  epoch time: 65.13
it: [10/59-223/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0006, lr: 0.000040, BT: 1.10, DT: 0.00
it: [20/59-223/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0009, lr: 0.000040, BT: 1.08, DT: 0.00
it: [30/59-223/250], rank: [1/1], Loss: 0.0012, Loss avg: 0.0031, lr: 0.000040, BT: 1.08, DT: 0.00
it: [40/59-223/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0025, lr: 0.000040, BT: 1.20, DT: 0.02
it: [50/59-223/250], rank: [1/1], Loss: 0.0065, Loss avg: 0.0022, lr: 0.000040, BT: 1.07, DT: 0.00
Train [223/250]	rank: [1/1], Loss: 0.0020, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.11, DT: 0.01,  epoch time: 65.54
it: [10/59-224/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0011, lr: 0.000038, BT: 1.07, DT: 0.00
it: [20/59-224/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0015, lr: 0.000038, BT: 1.07, DT: 0.00
it: [30/59-224/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0015, lr: 0.000038, BT: 1.07, DT: 0.00
it: [40/59-224/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0012, lr: 0.000038, BT: 1.07, DT: 0.00
it: [50/59-224/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0029, lr: 0.000038, BT: 1.19, DT: 0.00
Train [224/250]	rank: [1/1], Loss: 0.0026, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.11, DT: 0.01,  epoch time: 65.44
it: [10/59-225/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0004, lr: 0.000036, BT: 1.08, DT: 0.00
it: [20/59-225/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0006, lr: 0.000036, BT: 1.07, DT: 0.00
it: [30/59-225/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0007, lr: 0.000036, BT: 1.07, DT: 0.00
it: [40/59-225/250], rank: [1/1], Loss: 0.0017, Loss avg: 0.0007, lr: 0.000036, BT: 1.20, DT: 0.00
it: [50/59-225/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0006, lr: 0.000036, BT: 1.13, DT: 0.00
Train [225/250]	rank: [1/1], Loss: 0.0012, Acc: 0.9995, Bal Acc: 0.9993, BT: 1.11, DT: 0.01,  epoch time: 65.32
Test [225/250]	Acc: 0.9938, Bal Acc: 0.9924
it: [10/59-226/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0003, lr: 0.000034, BT: 1.15, DT: 0.00
it: [20/59-226/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0032, lr: 0.000034, BT: 1.06, DT: 0.00
it: [30/59-226/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0025, lr: 0.000034, BT: 1.06, DT: 0.00
it: [40/59-226/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0021, lr: 0.000034, BT: 1.09, DT: 0.00
it: [50/59-226/250], rank: [1/1], Loss: 0.0022, Loss avg: 0.0027, lr: 0.000034, BT: 1.08, DT: 0.00
Train [226/250]	rank: [1/1], Loss: 0.0026, Acc: 0.9984, Bal Acc: 0.9983, BT: 1.10, DT: 0.01,  epoch time: 65.07
it: [10/59-227/250], rank: [1/1], Loss: 0.0042, Loss avg: 0.0011, lr: 0.000032, BT: 1.08, DT: 0.00
it: [20/59-227/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0009, lr: 0.000032, BT: 1.08, DT: 0.00
it: [30/59-227/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0022, lr: 0.000032, BT: 1.06, DT: 0.00
it: [40/59-227/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0017, lr: 0.000032, BT: 1.06, DT: 0.00
it: [50/59-227/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0016, lr: 0.000032, BT: 1.06, DT: 0.00
Train [227/250]	rank: [1/1], Loss: 0.0015, Acc: 0.9995, Bal Acc: 0.9993, BT: 1.10, DT: 0.01,  epoch time: 65.03
it: [10/59-228/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0019, lr: 0.000031, BT: 1.06, DT: 0.00
it: [20/59-228/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0016, lr: 0.000031, BT: 1.06, DT: 0.00
it: [30/59-228/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0013, lr: 0.000031, BT: 1.06, DT: 0.00
it: [40/59-228/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0011, lr: 0.000031, BT: 1.07, DT: 0.00
it: [50/59-228/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0012, lr: 0.000031, BT: 1.19, DT: 0.01
Train [228/250]	rank: [1/1], Loss: 0.0013, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.10, DT: 0.01,  epoch time: 65.15
it: [10/59-229/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0006, lr: 0.000029, BT: 1.05, DT: 0.00
it: [20/59-229/250], rank: [1/1], Loss: 0.0044, Loss avg: 0.0020, lr: 0.000029, BT: 1.06, DT: 0.00
it: [30/59-229/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0025, lr: 0.000029, BT: 1.07, DT: 0.00
it: [40/59-229/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0020, lr: 0.000029, BT: 1.14, DT: 0.00
it: [50/59-229/250], rank: [1/1], Loss: 0.0048, Loss avg: 0.0020, lr: 0.000029, BT: 1.18, DT: 0.00
Train [229/250]	rank: [1/1], Loss: 0.0019, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.11, DT: 0.01,  epoch time: 65.28
it: [10/59-230/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0006, lr: 0.000027, BT: 1.07, DT: 0.00
it: [20/59-230/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0028, lr: 0.000027, BT: 1.07, DT: 0.00
it: [30/59-230/250], rank: [1/1], Loss: 0.0024, Loss avg: 0.0021, lr: 0.000027, BT: 1.18, DT: 0.01
it: [40/59-230/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0017, lr: 0.000027, BT: 1.07, DT: 0.00
it: [50/59-230/250], rank: [1/1], Loss: 0.0646, Loss avg: 0.0033, lr: 0.000027, BT: 1.07, DT: 0.00
Train [230/250]	rank: [1/1], Loss: 0.0029, Acc: 0.9989, Bal Acc: 0.9990, BT: 1.10, DT: 0.01,  epoch time: 65.10
Test [230/250]	Acc: 0.9958, Bal Acc: 0.9950
it: [10/59-231/250], rank: [1/1], Loss: 0.0033, Loss avg: 0.0009, lr: 0.000026, BT: 1.06, DT: 0.00
it: [20/59-231/250], rank: [1/1], Loss: 0.0015, Loss avg: 0.0006, lr: 0.000026, BT: 1.07, DT: 0.00
it: [30/59-231/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0005, lr: 0.000026, BT: 1.08, DT: 0.00
it: [40/59-231/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0005, lr: 0.000026, BT: 1.07, DT: 0.00
it: [50/59-231/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0005, lr: 0.000026, BT: 1.13, DT: 0.00
Train [231/250]	rank: [1/1], Loss: 0.0010, Acc: 0.9995, Bal Acc: 0.9995, BT: 1.10, DT: 0.01,  epoch time: 65.19
it: [10/59-232/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0047, lr: 0.000024, BT: 1.07, DT: 0.00
it: [20/59-232/250], rank: [1/1], Loss: 0.0049, Loss avg: 0.0028, lr: 0.000024, BT: 1.06, DT: 0.00
it: [30/59-232/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0022, lr: 0.000024, BT: 1.07, DT: 0.00
it: [40/59-232/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0019, lr: 0.000024, BT: 1.19, DT: 0.01
it: [50/59-232/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0018, lr: 0.000024, BT: 1.21, DT: 0.01
Train [232/250]	rank: [1/1], Loss: 0.0017, Acc: 0.9995, Bal Acc: 0.9995, BT: 1.11, DT: 0.01,  epoch time: 65.43
it: [10/59-233/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0039, lr: 0.000023, BT: 1.07, DT: 0.01
it: [20/59-233/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0029, lr: 0.000023, BT: 1.06, DT: 0.00
it: [30/59-233/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0024, lr: 0.000023, BT: 1.18, DT: 0.02
it: [40/59-233/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0018, lr: 0.000023, BT: 1.06, DT: 0.00
it: [50/59-233/250], rank: [1/1], Loss: 0.0142, Loss avg: 0.0022, lr: 0.000023, BT: 1.07, DT: 0.00
Train [233/250]	rank: [1/1], Loss: 0.0021, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.10, DT: 0.01,  epoch time: 64.95
it: [10/59-234/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0007, lr: 0.000021, BT: 1.07, DT: 0.00
it: [20/59-234/250], rank: [1/1], Loss: 0.0026, Loss avg: 0.0016, lr: 0.000021, BT: 1.18, DT: 0.01
it: [30/59-234/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0014, lr: 0.000021, BT: 1.09, DT: 0.00
it: [40/59-234/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0020, lr: 0.000021, BT: 1.07, DT: 0.00
it: [50/59-234/250], rank: [1/1], Loss: 0.0034, Loss avg: 0.0057, lr: 0.000021, BT: 1.07, DT: 0.00
Train [234/250]	rank: [1/1], Loss: 0.0049, Acc: 0.9989, Bal Acc: 0.9990, BT: 1.10, DT: 0.01,  epoch time: 65.05
it: [10/59-235/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0003, lr: 0.000020, BT: 1.17, DT: 0.00
it: [20/59-235/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0004, lr: 0.000020, BT: 1.18, DT: 0.01
it: [30/59-235/250], rank: [1/1], Loss: 0.0020, Loss avg: 0.0019, lr: 0.000020, BT: 1.07, DT: 0.00
it: [40/59-235/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0018, lr: 0.000020, BT: 1.07, DT: 0.00
it: [50/59-235/250], rank: [1/1], Loss: 0.0015, Loss avg: 0.0015, lr: 0.000020, BT: 1.06, DT: 0.00
Train [235/250]	rank: [1/1], Loss: 0.0014, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.10, DT: 0.01,  epoch time: 65.19
Test [235/250]	Acc: 0.9958, Bal Acc: 0.9949
it: [10/59-236/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0003, lr: 0.000019, BT: 1.07, DT: 0.00
it: [20/59-236/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0004, lr: 0.000019, BT: 1.07, DT: 0.00
it: [30/59-236/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0044, lr: 0.000019, BT: 1.21, DT: 0.01
it: [40/59-236/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0034, lr: 0.000019, BT: 1.16, DT: 0.01
it: [50/59-236/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0028, lr: 0.000019, BT: 1.07, DT: 0.00
Train [236/250]	rank: [1/1], Loss: 0.0025, Acc: 0.9995, Bal Acc: 0.9995, BT: 1.10, DT: 0.01,  epoch time: 64.88
it: [10/59-237/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0150, lr: 0.000018, BT: 1.06, DT: 0.00
it: [20/59-237/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0076, lr: 0.000018, BT: 1.16, DT: 0.00
it: [30/59-237/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0052, lr: 0.000018, BT: 1.17, DT: 0.01
it: [40/59-237/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0041, lr: 0.000018, BT: 1.07, DT: 0.00
it: [50/59-237/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0034, lr: 0.000018, BT: 1.09, DT: 0.00
Train [237/250]	rank: [1/1], Loss: 0.0045, Acc: 0.9984, Bal Acc: 0.9984, BT: 1.10, DT: 0.01,  epoch time: 64.94
it: [10/59-238/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0004, lr: 0.000017, BT: 1.06, DT: 0.00
it: [20/59-238/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0006, lr: 0.000017, BT: 1.18, DT: 0.01
it: [30/59-238/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0006, lr: 0.000017, BT: 1.07, DT: 0.00
it: [40/59-238/250], rank: [1/1], Loss: 0.0013, Loss avg: 0.0010, lr: 0.000017, BT: 1.06, DT: 0.00
it: [50/59-238/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0009, lr: 0.000017, BT: 1.07, DT: 0.00
Train [238/250]	rank: [1/1], Loss: 0.0015, Acc: 0.9995, Bal Acc: 0.9995, BT: 1.10, DT: 0.01,  epoch time: 64.93
it: [10/59-239/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0007, lr: 0.000016, BT: 1.17, DT: 0.01
it: [20/59-239/250], rank: [1/1], Loss: 0.0038, Loss avg: 0.0036, lr: 0.000016, BT: 1.07, DT: 0.00
it: [30/59-239/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0029, lr: 0.000016, BT: 1.08, DT: 0.00
it: [40/59-239/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0032, lr: 0.000016, BT: 1.08, DT: 0.00
it: [50/59-239/250], rank: [1/1], Loss: 0.0018, Loss avg: 0.0034, lr: 0.000016, BT: 1.06, DT: 0.00
Train [239/250]	rank: [1/1], Loss: 0.0030, Acc: 0.9989, Bal Acc: 0.9991, BT: 1.11, DT: 0.01,  epoch time: 65.37
it: [10/59-240/250], rank: [1/1], Loss: 0.0042, Loss avg: 0.0011, lr: 0.000015, BT: 1.09, DT: 0.00
it: [20/59-240/250], rank: [1/1], Loss: 0.0021, Loss avg: 0.0008, lr: 0.000015, BT: 1.08, DT: 0.00
it: [30/59-240/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0008, lr: 0.000015, BT: 1.07, DT: 0.00
it: [40/59-240/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0008, lr: 0.000015, BT: 1.07, DT: 0.00
it: [50/59-240/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0010, lr: 0.000015, BT: 1.07, DT: 0.00
Train [240/250]	rank: [1/1], Loss: 0.0009, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.10, DT: 0.01,  epoch time: 64.95
Test [240/250]	Acc: 0.9938, Bal Acc: 0.9923
it: [10/59-241/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0002, lr: 0.000014, BT: 1.07, DT: 0.00
it: [20/59-241/250], rank: [1/1], Loss: 0.0022, Loss avg: 0.0004, lr: 0.000014, BT: 1.13, DT: 0.00
it: [30/59-241/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0006, lr: 0.000014, BT: 1.22, DT: 0.01
it: [40/59-241/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0014, lr: 0.000014, BT: 1.06, DT: 0.00
it: [50/59-241/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0012, lr: 0.000014, BT: 1.07, DT: 0.00
Train [241/250]	rank: [1/1], Loss: 0.0011, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.10, DT: 0.01,  epoch time: 65.24
it: [10/59-242/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0046, lr: 0.000013, BT: 1.08, DT: 0.00
it: [20/59-242/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0083, lr: 0.000013, BT: 1.17, DT: 0.00
it: [30/59-242/250], rank: [1/1], Loss: 0.0049, Loss avg: 0.0059, lr: 0.000013, BT: 1.08, DT: 0.00
it: [40/59-242/250], rank: [1/1], Loss: 0.0034, Loss avg: 0.0047, lr: 0.000013, BT: 1.07, DT: 0.00
it: [50/59-242/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0039, lr: 0.000013, BT: 1.07, DT: 0.00
Train [242/250]	rank: [1/1], Loss: 0.0034, Acc: 0.9984, Bal Acc: 0.9987, BT: 1.10, DT: 0.01,  epoch time: 64.90
it: [10/59-243/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0007, lr: 0.000012, BT: 1.19, DT: 0.01
it: [20/59-243/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0007, lr: 0.000012, BT: 1.07, DT: 0.00
it: [30/59-243/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0014, lr: 0.000012, BT: 1.08, DT: 0.00
it: [40/59-243/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0012, lr: 0.000012, BT: 1.08, DT: 0.00
it: [50/59-243/250], rank: [1/1], Loss: 0.0087, Loss avg: 0.0012, lr: 0.000012, BT: 1.07, DT: 0.00
Train [243/250]	rank: [1/1], Loss: 0.0011, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.10, DT: 0.01,  epoch time: 64.99
it: [10/59-244/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0004, lr: 0.000012, BT: 1.07, DT: 0.00
it: [20/59-244/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0006, lr: 0.000012, BT: 1.07, DT: 0.00
it: [30/59-244/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0006, lr: 0.000012, BT: 1.09, DT: 0.00
it: [40/59-244/250], rank: [1/1], Loss: 0.0053, Loss avg: 0.0007, lr: 0.000012, BT: 1.09, DT: 0.00
it: [50/59-244/250], rank: [1/1], Loss: 0.0037, Loss avg: 0.0007, lr: 0.000012, BT: 1.19, DT: 0.00
Train [244/250]	rank: [1/1], Loss: 0.0007, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.11, DT: 0.01,  epoch time: 65.67
it: [10/59-245/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0011, lr: 0.000011, BT: 1.07, DT: 0.00
it: [20/59-245/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0008, lr: 0.000011, BT: 1.07, DT: 0.00
it: [30/59-245/250], rank: [1/1], Loss: 0.0052, Loss avg: 0.0012, lr: 0.000011, BT: 1.07, DT: 0.00
it: [40/59-245/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0012, lr: 0.000011, BT: 1.15, DT: 0.01
it: [50/59-245/250], rank: [1/1], Loss: 0.0026, Loss avg: 0.0020, lr: 0.000011, BT: 1.06, DT: 0.00
Train [245/250]	rank: [1/1], Loss: 0.0019, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.12, DT: 0.02,  epoch time: 65.93
Test [245/250]	Acc: 0.9958, Bal Acc: 0.9950
it: [10/59-246/250], rank: [1/1], Loss: 0.0049, Loss avg: 0.0013, lr: 0.000011, BT: 1.18, DT: 0.00
it: [20/59-246/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0010, lr: 0.000011, BT: 1.06, DT: 0.00
it: [30/59-246/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0011, lr: 0.000011, BT: 1.07, DT: 0.00
it: [40/59-246/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0021, lr: 0.000011, BT: 1.07, DT: 0.00
it: [50/59-246/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0019, lr: 0.000011, BT: 1.13, DT: 0.00
Train [246/250]	rank: [1/1], Loss: 0.0017, Acc: 0.9995, Bal Acc: 0.9994, BT: 1.10, DT: 0.01,  epoch time: 65.05
it: [10/59-247/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0003, lr: 0.000011, BT: 1.06, DT: 0.00
it: [20/59-247/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0004, lr: 0.000011, BT: 1.08, DT: 0.00
it: [30/59-247/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0007, lr: 0.000011, BT: 1.08, DT: 0.00
it: [40/59-247/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0007, lr: 0.000011, BT: 1.07, DT: 0.00
it: [50/59-247/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0008, lr: 0.000011, BT: 1.12, DT: 0.00
Train [247/250]	rank: [1/1], Loss: 0.0010, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.11, DT: 0.01,  epoch time: 65.62
it: [10/59-248/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0008, lr: 0.000010, BT: 1.07, DT: 0.00
it: [20/59-248/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0024, lr: 0.000010, BT: 1.06, DT: 0.00
it: [30/59-248/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0018, lr: 0.000010, BT: 1.07, DT: 0.00
it: [40/59-248/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0017, lr: 0.000010, BT: 1.07, DT: 0.00
it: [50/59-248/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0016, lr: 0.000010, BT: 1.15, DT: 0.00
Train [248/250]	rank: [1/1], Loss: 0.0014, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.11, DT: 0.01,  epoch time: 65.42
it: [10/59-249/250], rank: [1/1], Loss: 0.0025, Loss avg: 0.0009, lr: 0.000010, BT: 1.07, DT: 0.00
it: [20/59-249/250], rank: [1/1], Loss: 0.0032, Loss avg: 0.0014, lr: 0.000010, BT: 1.07, DT: 0.00
it: [30/59-249/250], rank: [1/1], Loss: 0.0028, Loss avg: 0.0011, lr: 0.000010, BT: 1.07, DT: 0.00
it: [40/59-249/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0036, lr: 0.000010, BT: 1.16, DT: 0.01
it: [50/59-249/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0030, lr: 0.000010, BT: 1.08, DT: 0.00
Train [249/250]	rank: [1/1], Loss: 0.0026, Acc: 0.9995, Bal Acc: 0.9996, BT: 1.10, DT: 0.01,  epoch time: 65.12
it: [10/59-250/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0009, lr: 0.000010, BT: 1.07, DT: 0.00
it: [20/59-250/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0010, lr: 0.000010, BT: 1.07, DT: 0.00
it: [30/59-250/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0008, lr: 0.000010, BT: 1.15, DT: 0.00
it: [40/59-250/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0007, lr: 0.000010, BT: 1.08, DT: 0.00
it: [50/59-250/250], rank: [1/1], Loss: 0.0001, Loss avg: 0.0007, lr: 0.000010, BT: 1.08, DT: 0.00
Train [250/250]	rank: [1/1], Loss: 0.0007, Acc: 1.0000, Bal Acc: 1.0000, BT: 1.11, DT: 0.01,  epoch time: 65.34
Test [250/250]	Acc: 0.9958, Bal Acc: 0.9949
Training finished - best test acc: 0.9958 at ep.: 250, time: 3701.739851474762
