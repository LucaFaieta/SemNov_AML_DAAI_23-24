Arguments: Namespace(local_rank=None, use_sync_bn=False, use_amp=False, script_mode='train', config='cfgs/pn2-msg.yaml', seed=1, epochs=250, batch_size=32, num_workers=4, resume='/content/drive/MyDrive/SemNov_AML_DAAI_23-24/outputs/Pointnet_SR1_cosine/models/model_last.pth', apply_fix_cellphone=True, data_root='./3D_OS_release_data', checkpoints_dir='outputs', exp_name='Pointnet_SR1_cosine', eval_step=1, save_step=10, ckpt_path=None, src='SR1', sonn_split='main_split', sonn_h5_name='objectdataset.h5', augm_set='rw', grad_norm_clip=-1, num_points=1024, num_points_test=2048, wandb_name=None, wandb_group='md-2-sonn-augmCorr', wandb_proj='AML_DAAI_proj23_24_Pointnet_SR1_cosine', loss='cosine', cs=False, cs_gan_lr=0.0002, cs_beta=0.1, save_feats=None, corruption=None, tar1='none', tar2='none', log_dir='outputs/Pointnet_SR1_cosine', tb_dir='outputs/Pointnet_SR1_cosine/tb-logs', models_dir='outputs/Pointnet_SR1_cosine/models', backup_dir='outputs/Pointnet_SR1_cosine/backup-code')
Config: {'optimizer': {'type': 'adam', 'skip_wd': [], 'weight_decay': 0.0001, 'kwargs': {'lr': 0.001}}, 'scheduler': {'type': 'CosLR', 'kwargs': {'t_initial': 250, 'cycle_limit': 1, 'lr_min': 1e-05}}, 'model': {'ENCO_NAME': 'pn2-msg', 'dropout': 0.5, 'cla_input_dim': 1024, 'act': 'relu'}}
World size: 1

SR1 train synset: {'chair': 0, 'bookshelf': 1, 'door': 2, 'sink': 3, 'sofa': 4}
Source: SR1
Num training classes: 5
Model: 
Classifier(
  (enco): Pointnet2_MSG_Y(
    (sa1): PointNetSetAbstractionMsg(
      (conv_blocks): ModuleList(
        (0): ModuleList(
          (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ModuleList(
          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): ModuleList(
          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bn_blocks): ModuleList(
        (0): ModuleList(
          (0-1): 2 x BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): ModuleList(
          (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): ModuleList(
          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (sa2): PointNetSetAbstractionMsg(
      (conv_blocks): ModuleList(
        (0): ModuleList(
          (0): Conv2d(323, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (1-2): 2 x ModuleList(
          (0): Conv2d(323, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (bn_blocks): ModuleList(
        (0): ModuleList(
          (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1-2): 2 x ModuleList(
          (0-1): 2 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (sa3): PointNetSetAbstraction(
      (mlp_convs): ModuleList(
        (0): Conv2d(643, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
      )
      (mlp_bns): ModuleList(
        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (penultimate): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=False)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=512, out_features=256, bias=True)
  )
  (head): MarginCosineProduct(in_features=256, out_features=5, s=30.0, m=0)
)

param count: 
1.7373 M
Loss: cosine

Restart training from checkpoint /content/drive/MyDrive/SemNov_AML_DAAI_23-24/outputs/Pointnet_SR1_cosine/models/model_last.pth
it: [10/74-81/250], rank: [1/1], Loss: 0.0080, Loss avg: 0.0137, lr: 0.000770, BT: 1.03, DT: 0.00
it: [20/74-81/250], rank: [1/1], Loss: 0.0085, Loss avg: 0.0274, lr: 0.000770, BT: 1.13, DT: 0.00
it: [30/74-81/250], rank: [1/1], Loss: 0.0027, Loss avg: 0.0263, lr: 0.000770, BT: 1.06, DT: 0.00
it: [40/74-81/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0254, lr: 0.000770, BT: 1.08, DT: 0.01
it: [50/74-81/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0314, lr: 0.000770, BT: 1.15, DT: 0.00
it: [60/74-81/250], rank: [1/1], Loss: 0.0034, Loss avg: 0.0306, lr: 0.000770, BT: 1.07, DT: 0.00
it: [70/74-81/250], rank: [1/1], Loss: 0.0039, Loss avg: 0.0286, lr: 0.000770, BT: 1.16, DT: 0.00
Train [81/250]	rank: [1/1], Loss: 0.0279, Acc: 0.9911, Bal Acc: 0.9855, BT: 1.29, DT: 0.01,  epoch time: 95.24
Test [81/250]	Acc: 0.9594, Bal Acc: 0.9460
it: [10/74-82/250], rank: [1/1], Loss: 0.0354, Loss avg: 0.0108, lr: 0.000765, BT: 1.10, DT: 0.00
it: [20/74-82/250], rank: [1/1], Loss: 0.0098, Loss avg: 0.0245, lr: 0.000765, BT: 1.11, DT: 0.00
it: [30/74-82/250], rank: [1/1], Loss: 0.0037, Loss avg: 0.0209, lr: 0.000765, BT: 1.22, DT: 0.00
it: [40/74-82/250], rank: [1/1], Loss: 0.0013, Loss avg: 0.0205, lr: 0.000765, BT: 1.08, DT: 0.00
it: [50/74-82/250], rank: [1/1], Loss: 0.0605, Loss avg: 0.0233, lr: 0.000765, BT: 1.08, DT: 0.00
it: [60/74-82/250], rank: [1/1], Loss: 0.0027, Loss avg: 0.0202, lr: 0.000765, BT: 1.16, DT: 0.00
it: [70/74-82/250], rank: [1/1], Loss: 0.0172, Loss avg: 0.0197, lr: 0.000765, BT: 1.06, DT: 0.00
Train [82/250]	rank: [1/1], Loss: 0.0228, Acc: 0.9907, Bal Acc: 0.9869, BT: 1.15, DT: 0.01,  epoch time: 85.15
Test [82/250]	Acc: 0.9750, Bal Acc: 0.9559
it: [10/74-83/250], rank: [1/1], Loss: 0.0020, Loss avg: 0.0232, lr: 0.000760, BT: 1.20, DT: 0.01
it: [20/74-83/250], rank: [1/1], Loss: 0.0070, Loss avg: 0.0371, lr: 0.000760, BT: 1.27, DT: 0.03
it: [30/74-83/250], rank: [1/1], Loss: 0.0675, Loss avg: 0.0385, lr: 0.000760, BT: 1.09, DT: 0.00
it: [40/74-83/250], rank: [1/1], Loss: 0.0878, Loss avg: 0.0330, lr: 0.000760, BT: 1.09, DT: 0.00
it: [50/74-83/250], rank: [1/1], Loss: 0.0022, Loss avg: 0.0354, lr: 0.000760, BT: 1.21, DT: 0.01
it: [60/74-83/250], rank: [1/1], Loss: 0.0061, Loss avg: 0.0378, lr: 0.000760, BT: 1.09, DT: 0.00
it: [70/74-83/250], rank: [1/1], Loss: 0.0639, Loss avg: 0.0405, lr: 0.000760, BT: 1.05, DT: 0.00
Train [83/250]	rank: [1/1], Loss: 0.0405, Acc: 0.9848, Bal Acc: 0.9735, BT: 1.15, DT: 0.01,  epoch time: 85.21
Test [83/250]	Acc: 0.9719, Bal Acc: 0.9465
it: [10/74-84/250], rank: [1/1], Loss: 0.0024, Loss avg: 0.0362, lr: 0.000754, BT: 1.08, DT: 0.00
it: [20/74-84/250], rank: [1/1], Loss: 0.0013, Loss avg: 0.0331, lr: 0.000754, BT: 1.10, DT: 0.00
it: [30/74-84/250], rank: [1/1], Loss: 0.0119, Loss avg: 0.0265, lr: 0.000754, BT: 1.19, DT: 0.00
it: [40/74-84/250], rank: [1/1], Loss: 0.0025, Loss avg: 0.0284, lr: 0.000754, BT: 1.08, DT: 0.00
it: [50/74-84/250], rank: [1/1], Loss: 0.0387, Loss avg: 0.0412, lr: 0.000754, BT: 1.10, DT: 0.00
it: [60/74-84/250], rank: [1/1], Loss: 0.0098, Loss avg: 0.0377, lr: 0.000754, BT: 1.20, DT: 0.01
it: [70/74-84/250], rank: [1/1], Loss: 0.2151, Loss avg: 0.0363, lr: 0.000754, BT: 1.05, DT: 0.00
Train [84/250]	rank: [1/1], Loss: 0.0350, Acc: 0.9886, Bal Acc: 0.9784, BT: 1.14, DT: 0.01,  epoch time: 84.51
Test [84/250]	Acc: 0.9719, Bal Acc: 0.9534
it: [10/74-85/250], rank: [1/1], Loss: 0.0189, Loss avg: 0.0253, lr: 0.000749, BT: 1.21, DT: 0.00
it: [20/74-85/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0169, lr: 0.000749, BT: 1.09, DT: 0.00
it: [30/74-85/250], rank: [1/1], Loss: 0.1042, Loss avg: 0.0217, lr: 0.000749, BT: 1.08, DT: 0.00
it: [40/74-85/250], rank: [1/1], Loss: 0.0497, Loss avg: 0.0203, lr: 0.000749, BT: 1.22, DT: 0.01
it: [50/74-85/250], rank: [1/1], Loss: 0.0035, Loss avg: 0.0212, lr: 0.000749, BT: 1.08, DT: 0.00
it: [60/74-85/250], rank: [1/1], Loss: 0.0013, Loss avg: 0.0337, lr: 0.000749, BT: 1.09, DT: 0.00
it: [70/74-85/250], rank: [1/1], Loss: 0.0115, Loss avg: 0.0353, lr: 0.000749, BT: 1.15, DT: 0.00
Train [85/250]	rank: [1/1], Loss: 0.0430, Acc: 0.9869, Bal Acc: 0.9803, BT: 1.14, DT: 0.01,  epoch time: 84.18
Test [85/250]	Acc: 0.9719, Bal Acc: 0.9464
it: [10/74-86/250], rank: [1/1], Loss: 0.0044, Loss avg: 0.0570, lr: 0.000743, BT: 1.09, DT: 0.00
it: [20/74-86/250], rank: [1/1], Loss: 0.0104, Loss avg: 0.0410, lr: 0.000743, BT: 1.20, DT: 0.00
it: [30/74-86/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0354, lr: 0.000743, BT: 1.09, DT: 0.00
it: [40/74-86/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0306, lr: 0.000743, BT: 1.08, DT: 0.00
it: [50/74-86/250], rank: [1/1], Loss: 0.0130, Loss avg: 0.0301, lr: 0.000743, BT: 1.20, DT: 0.00
it: [60/74-86/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0349, lr: 0.000743, BT: 1.10, DT: 0.00
it: [70/74-86/250], rank: [1/1], Loss: 0.0035, Loss avg: 0.0327, lr: 0.000743, BT: 1.06, DT: 0.00
Train [86/250]	rank: [1/1], Loss: 0.0350, Acc: 0.9882, Bal Acc: 0.9728, BT: 1.14, DT: 0.01,  epoch time: 84.52
Test [86/250]	Acc: 0.9750, Bal Acc: 0.9657
it: [10/74-87/250], rank: [1/1], Loss: 0.0106, Loss avg: 0.0180, lr: 0.000738, BT: 1.20, DT: 0.01
it: [20/74-87/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0218, lr: 0.000738, BT: 1.09, DT: 0.00
it: [30/74-87/250], rank: [1/1], Loss: 0.0437, Loss avg: 0.0202, lr: 0.000738, BT: 1.09, DT: 0.00
it: [40/74-87/250], rank: [1/1], Loss: 0.0034, Loss avg: 0.0202, lr: 0.000738, BT: 1.16, DT: 0.00
it: [50/74-87/250], rank: [1/1], Loss: 0.0046, Loss avg: 0.0239, lr: 0.000738, BT: 1.10, DT: 0.00
it: [60/74-87/250], rank: [1/1], Loss: 0.0069, Loss avg: 0.0235, lr: 0.000738, BT: 1.08, DT: 0.00
it: [70/74-87/250], rank: [1/1], Loss: 0.2339, Loss avg: 0.0248, lr: 0.000738, BT: 1.11, DT: 0.00
Train [87/250]	rank: [1/1], Loss: 0.0282, Acc: 0.9907, Bal Acc: 0.9867, BT: 1.14, DT: 0.01,  epoch time: 84.16
Test [87/250]	Acc: 0.9688, Bal Acc: 0.9514
it: [10/74-88/250], rank: [1/1], Loss: 0.0787, Loss avg: 0.0241, lr: 0.000732, BT: 1.10, DT: 0.00
it: [20/74-88/250], rank: [1/1], Loss: 0.0049, Loss avg: 0.0173, lr: 0.000732, BT: 1.20, DT: 0.00
it: [30/74-88/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0155, lr: 0.000732, BT: 1.09, DT: 0.00
it: [40/74-88/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0215, lr: 0.000732, BT: 1.11, DT: 0.00
it: [50/74-88/250], rank: [1/1], Loss: 0.0033, Loss avg: 0.0214, lr: 0.000732, BT: 1.21, DT: 0.00
it: [60/74-88/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0200, lr: 0.000732, BT: 1.10, DT: 0.00
it: [70/74-88/250], rank: [1/1], Loss: 0.0023, Loss avg: 0.0217, lr: 0.000732, BT: 1.06, DT: 0.00
Train [88/250]	rank: [1/1], Loss: 0.0229, Acc: 0.9920, Bal Acc: 0.9857, BT: 1.14, DT: 0.01,  epoch time: 84.51
Test [88/250]	Acc: 0.9656, Bal Acc: 0.9509
it: [10/74-89/250], rank: [1/1], Loss: 0.0169, Loss avg: 0.0412, lr: 0.000727, BT: 1.18, DT: 0.00
it: [20/74-89/250], rank: [1/1], Loss: 0.0277, Loss avg: 0.0324, lr: 0.000727, BT: 1.10, DT: 0.00
it: [30/74-89/250], rank: [1/1], Loss: 0.1803, Loss avg: 0.0348, lr: 0.000727, BT: 1.24, DT: 0.01
it: [40/74-89/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0290, lr: 0.000727, BT: 1.19, DT: 0.00
it: [50/74-89/250], rank: [1/1], Loss: 0.0559, Loss avg: 0.0267, lr: 0.000727, BT: 1.09, DT: 0.00
it: [60/74-89/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0255, lr: 0.000727, BT: 1.08, DT: 0.00
it: [70/74-89/250], rank: [1/1], Loss: 0.0020, Loss avg: 0.0243, lr: 0.000727, BT: 1.11, DT: 0.00
Train [89/250]	rank: [1/1], Loss: 0.0231, Acc: 0.9920, Bal Acc: 0.9906, BT: 1.14, DT: 0.01,  epoch time: 84.69
Test [89/250]	Acc: 0.9750, Bal Acc: 0.9671
it: [10/74-90/250], rank: [1/1], Loss: 0.0160, Loss avg: 0.0177, lr: 0.000721, BT: 1.10, DT: 0.00
it: [20/74-90/250], rank: [1/1], Loss: 0.0104, Loss avg: 0.0244, lr: 0.000721, BT: 1.18, DT: 0.00
it: [30/74-90/250], rank: [1/1], Loss: 0.0185, Loss avg: 0.0222, lr: 0.000721, BT: 1.11, DT: 0.00
it: [40/74-90/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0224, lr: 0.000721, BT: 1.10, DT: 0.00
it: [50/74-90/250], rank: [1/1], Loss: 0.0026, Loss avg: 0.0222, lr: 0.000721, BT: 1.18, DT: 0.00
it: [60/74-90/250], rank: [1/1], Loss: 0.0119, Loss avg: 0.0256, lr: 0.000721, BT: 1.08, DT: 0.00
it: [70/74-90/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0253, lr: 0.000721, BT: 1.05, DT: 0.00
Train [90/250]	rank: [1/1], Loss: 0.0244, Acc: 0.9924, Bal Acc: 0.9856, BT: 1.14, DT: 0.01,  epoch time: 84.57
Test [90/250]	Acc: 0.9719, Bal Acc: 0.9451
it: [10/74-91/250], rank: [1/1], Loss: 0.0132, Loss avg: 0.0199, lr: 0.000716, BT: 1.11, DT: 0.00
it: [20/74-91/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0259, lr: 0.000716, BT: 1.09, DT: 0.00
it: [30/74-91/250], rank: [1/1], Loss: 0.0392, Loss avg: 0.0223, lr: 0.000716, BT: 1.27, DT: 0.01
it: [40/74-91/250], rank: [1/1], Loss: 0.2389, Loss avg: 0.0293, lr: 0.000716, BT: 1.19, DT: 0.00
it: [50/74-91/250], rank: [1/1], Loss: 0.0133, Loss avg: 0.0296, lr: 0.000716, BT: 1.10, DT: 0.00
it: [60/74-91/250], rank: [1/1], Loss: 0.0041, Loss avg: 0.0291, lr: 0.000716, BT: 1.10, DT: 0.00
it: [70/74-91/250], rank: [1/1], Loss: 0.1025, Loss avg: 0.0282, lr: 0.000716, BT: 1.11, DT: 0.00
Train [91/250]	rank: [1/1], Loss: 0.0281, Acc: 0.9916, Bal Acc: 0.9827, BT: 1.15, DT: 0.01,  epoch time: 84.85
Test [91/250]	Acc: 0.9656, Bal Acc: 0.9520
it: [10/74-92/250], rank: [1/1], Loss: 0.1006, Loss avg: 0.0310, lr: 0.000710, BT: 1.09, DT: 0.00
it: [20/74-92/250], rank: [1/1], Loss: 0.0027, Loss avg: 0.0254, lr: 0.000710, BT: 1.18, DT: 0.00
it: [30/74-92/250], rank: [1/1], Loss: 0.0100, Loss avg: 0.0306, lr: 0.000710, BT: 1.10, DT: 0.00
it: [40/74-92/250], rank: [1/1], Loss: 0.0080, Loss avg: 0.0397, lr: 0.000710, BT: 1.08, DT: 0.00
it: [50/74-92/250], rank: [1/1], Loss: 0.0655, Loss avg: 0.0414, lr: 0.000710, BT: 1.19, DT: 0.00
it: [60/74-92/250], rank: [1/1], Loss: 0.0016, Loss avg: 0.0367, lr: 0.000710, BT: 1.09, DT: 0.00
it: [70/74-92/250], rank: [1/1], Loss: 0.0900, Loss avg: 0.0363, lr: 0.000710, BT: 1.05, DT: 0.00
Train [92/250]	rank: [1/1], Loss: 0.0351, Acc: 0.9869, Bal Acc: 0.9776, BT: 1.14, DT: 0.01,  epoch time: 84.42
Test [92/250]	Acc: 0.9719, Bal Acc: 0.9556
it: [10/74-93/250], rank: [1/1], Loss: 0.0038, Loss avg: 0.0493, lr: 0.000704, BT: 1.08, DT: 0.00
it: [20/74-93/250], rank: [1/1], Loss: 0.0640, Loss avg: 0.0620, lr: 0.000704, BT: 1.08, DT: 0.00
it: [30/74-93/250], rank: [1/1], Loss: 0.0111, Loss avg: 0.0800, lr: 0.000704, BT: 1.21, DT: 0.01
it: [40/74-93/250], rank: [1/1], Loss: 0.0028, Loss avg: 0.0689, lr: 0.000704, BT: 1.08, DT: 0.00
it: [50/74-93/250], rank: [1/1], Loss: 0.0104, Loss avg: 0.0649, lr: 0.000704, BT: 1.09, DT: 0.00
it: [60/74-93/250], rank: [1/1], Loss: 0.2164, Loss avg: 0.0679, lr: 0.000704, BT: 1.24, DT: 0.01
it: [70/74-93/250], rank: [1/1], Loss: 0.0058, Loss avg: 0.0634, lr: 0.000704, BT: 1.06, DT: 0.00
Train [93/250]	rank: [1/1], Loss: 0.0620, Acc: 0.9806, Bal Acc: 0.9721, BT: 1.14, DT: 0.01,  epoch time: 84.80
Test [93/250]	Acc: 0.9781, Bal Acc: 0.9677
it: [10/74-94/250], rank: [1/1], Loss: 0.0217, Loss avg: 0.0126, lr: 0.000699, BT: 1.19, DT: 0.00
it: [20/74-94/250], rank: [1/1], Loss: 0.0147, Loss avg: 0.0330, lr: 0.000699, BT: 1.20, DT: 0.01
it: [30/74-94/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0306, lr: 0.000699, BT: 1.08, DT: 0.00
it: [40/74-94/250], rank: [1/1], Loss: 0.0356, Loss avg: 0.0375, lr: 0.000699, BT: 1.08, DT: 0.00
it: [50/74-94/250], rank: [1/1], Loss: 0.0639, Loss avg: 0.0463, lr: 0.000699, BT: 1.21, DT: 0.00
it: [60/74-94/250], rank: [1/1], Loss: 0.0791, Loss avg: 0.0454, lr: 0.000699, BT: 1.08, DT: 0.00
it: [70/74-94/250], rank: [1/1], Loss: 0.0016, Loss avg: 0.0419, lr: 0.000699, BT: 1.05, DT: 0.00
Train [94/250]	rank: [1/1], Loss: 0.0419, Acc: 0.9856, Bal Acc: 0.9742, BT: 1.14, DT: 0.01,  epoch time: 84.64
Test [94/250]	Acc: 0.9656, Bal Acc: 0.9449
it: [10/74-95/250], rank: [1/1], Loss: 0.0060, Loss avg: 0.0312, lr: 0.000693, BT: 1.09, DT: 0.00
it: [20/74-95/250], rank: [1/1], Loss: 0.0017, Loss avg: 0.0219, lr: 0.000693, BT: 1.13, DT: 0.00
it: [30/74-95/250], rank: [1/1], Loss: 0.0122, Loss avg: 0.0241, lr: 0.000693, BT: 1.19, DT: 0.00
it: [40/74-95/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0238, lr: 0.000693, BT: 1.09, DT: 0.00
it: [50/74-95/250], rank: [1/1], Loss: 0.0271, Loss avg: 0.0313, lr: 0.000693, BT: 1.09, DT: 0.00
it: [60/74-95/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0317, lr: 0.000693, BT: 1.21, DT: 0.01
it: [70/74-95/250], rank: [1/1], Loss: 0.1473, Loss avg: 0.0359, lr: 0.000693, BT: 1.05, DT: 0.00
Train [95/250]	rank: [1/1], Loss: 0.0357, Acc: 0.9865, Bal Acc: 0.9731, BT: 1.15, DT: 0.01,  epoch time: 84.91
Test [95/250]	Acc: 0.9750, Bal Acc: 0.9656
it: [10/74-96/250], rank: [1/1], Loss: 0.0455, Loss avg: 0.0343, lr: 0.000687, BT: 1.25, DT: 0.01
it: [20/74-96/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0287, lr: 0.000687, BT: 1.11, DT: 0.00
it: [30/74-96/250], rank: [1/1], Loss: 0.0063, Loss avg: 0.0287, lr: 0.000687, BT: 1.09, DT: 0.00
it: [40/74-96/250], rank: [1/1], Loss: 0.0173, Loss avg: 0.0294, lr: 0.000687, BT: 1.22, DT: 0.00
it: [50/74-96/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0258, lr: 0.000687, BT: 1.09, DT: 0.00
it: [60/74-96/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0226, lr: 0.000687, BT: 1.09, DT: 0.00
it: [70/74-96/250], rank: [1/1], Loss: 0.0893, Loss avg: 0.0240, lr: 0.000687, BT: 1.15, DT: 0.00
Train [96/250]	rank: [1/1], Loss: 0.0229, Acc: 0.9920, Bal Acc: 0.9845, BT: 1.14, DT: 0.01,  epoch time: 84.64
Test [96/250]	Acc: 0.9812, Bal Acc: 0.9634
it: [10/74-97/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0299, lr: 0.000681, BT: 1.10, DT: 0.00
it: [20/74-97/250], rank: [1/1], Loss: 0.0246, Loss avg: 0.0326, lr: 0.000681, BT: 1.20, DT: 0.00
it: [30/74-97/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0338, lr: 0.000681, BT: 1.10, DT: 0.00
it: [40/74-97/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0362, lr: 0.000681, BT: 1.10, DT: 0.00
it: [50/74-97/250], rank: [1/1], Loss: 0.0024, Loss avg: 0.0317, lr: 0.000681, BT: 1.23, DT: 0.01
it: [60/74-97/250], rank: [1/1], Loss: 0.1209, Loss avg: 0.0321, lr: 0.000681, BT: 1.11, DT: 0.00
it: [70/74-97/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0287, lr: 0.000681, BT: 1.06, DT: 0.00
Train [97/250]	rank: [1/1], Loss: 0.0276, Acc: 0.9890, Bal Acc: 0.9763, BT: 1.14, DT: 0.01,  epoch time: 84.53
Test [97/250]	Acc: 0.9594, Bal Acc: 0.9472
it: [10/74-98/250], rank: [1/1], Loss: 0.0020, Loss avg: 0.0061, lr: 0.000676, BT: 1.20, DT: 0.01
it: [20/74-98/250], rank: [1/1], Loss: 0.0902, Loss avg: 0.0217, lr: 0.000676, BT: 1.11, DT: 0.00
it: [30/74-98/250], rank: [1/1], Loss: 0.0077, Loss avg: 0.0194, lr: 0.000676, BT: 1.09, DT: 0.00
it: [40/74-98/250], rank: [1/1], Loss: 0.0026, Loss avg: 0.0260, lr: 0.000676, BT: 1.17, DT: 0.00
it: [50/74-98/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0255, lr: 0.000676, BT: 1.09, DT: 0.00
it: [60/74-98/250], rank: [1/1], Loss: 0.0477, Loss avg: 0.0269, lr: 0.000676, BT: 1.09, DT: 0.00
it: [70/74-98/250], rank: [1/1], Loss: 0.0156, Loss avg: 0.0268, lr: 0.000676, BT: 1.13, DT: 0.00
Train [98/250]	rank: [1/1], Loss: 0.0278, Acc: 0.9911, Bal Acc: 0.9785, BT: 1.14, DT: 0.01,  epoch time: 84.56
Test [98/250]	Acc: 0.9812, Bal Acc: 0.9704
it: [10/74-99/250], rank: [1/1], Loss: 0.0482, Loss avg: 0.0202, lr: 0.000670, BT: 1.08, DT: 0.00
it: [20/74-99/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0227, lr: 0.000670, BT: 1.14, DT: 0.00
it: [30/74-99/250], rank: [1/1], Loss: 0.0110, Loss avg: 0.0246, lr: 0.000670, BT: 1.09, DT: 0.00
it: [40/74-99/250], rank: [1/1], Loss: 0.1319, Loss avg: 0.0266, lr: 0.000670, BT: 1.09, DT: 0.00
it: [50/74-99/250], rank: [1/1], Loss: 0.0217, Loss avg: 0.0253, lr: 0.000670, BT: 1.17, DT: 0.00
it: [60/74-99/250], rank: [1/1], Loss: 0.1161, Loss avg: 0.0283, lr: 0.000670, BT: 1.09, DT: 0.00
it: [70/74-99/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0304, lr: 0.000670, BT: 1.05, DT: 0.00
Train [99/250]	rank: [1/1], Loss: 0.0289, Acc: 0.9894, Bal Acc: 0.9822, BT: 1.14, DT: 0.01,  epoch time: 84.53
Test [99/250]	Acc: 0.9812, Bal Acc: 0.9551
it: [10/74-100/250], rank: [1/1], Loss: 0.0665, Loss avg: 0.0102, lr: 0.000664, BT: 1.18, DT: 0.01
it: [20/74-100/250], rank: [1/1], Loss: 0.0054, Loss avg: 0.0134, lr: 0.000664, BT: 1.09, DT: 0.00
it: [30/74-100/250], rank: [1/1], Loss: 0.0053, Loss avg: 0.0221, lr: 0.000664, BT: 1.09, DT: 0.00
it: [40/74-100/250], rank: [1/1], Loss: 0.1248, Loss avg: 0.0263, lr: 0.000664, BT: 1.17, DT: 0.00
it: [50/74-100/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0276, lr: 0.000664, BT: 1.08, DT: 0.00
it: [60/74-100/250], rank: [1/1], Loss: 0.0077, Loss avg: 0.0241, lr: 0.000664, BT: 1.09, DT: 0.00
it: [70/74-100/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0227, lr: 0.000664, BT: 1.14, DT: 0.00
Train [100/250]	rank: [1/1], Loss: 0.0223, Acc: 0.9924, Bal Acc: 0.9833, BT: 1.14, DT: 0.01,  epoch time: 84.51
Test [100/250]	Acc: 0.9688, Bal Acc: 0.9609
it: [10/74-101/250], rank: [1/1], Loss: 0.0021, Loss avg: 0.0061, lr: 0.000658, BT: 1.08, DT: 0.00
it: [20/74-101/250], rank: [1/1], Loss: 0.0022, Loss avg: 0.0078, lr: 0.000658, BT: 1.21, DT: 0.00
it: [30/74-101/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0109, lr: 0.000658, BT: 1.10, DT: 0.00
it: [40/74-101/250], rank: [1/1], Loss: 0.0031, Loss avg: 0.0108, lr: 0.000658, BT: 1.09, DT: 0.00
it: [50/74-101/250], rank: [1/1], Loss: 0.0016, Loss avg: 0.0134, lr: 0.000658, BT: 1.21, DT: 0.01
it: [60/74-101/250], rank: [1/1], Loss: 0.1735, Loss avg: 0.0193, lr: 0.000658, BT: 1.08, DT: 0.00
it: [70/74-101/250], rank: [1/1], Loss: 0.0435, Loss avg: 0.0214, lr: 0.000658, BT: 1.06, DT: 0.00
Train [101/250]	rank: [1/1], Loss: 0.0208, Acc: 0.9932, Bal Acc: 0.9884, BT: 1.15, DT: 0.01,  epoch time: 84.85
Test [101/250]	Acc: 0.9812, Bal Acc: 0.9505
it: [10/74-102/250], rank: [1/1], Loss: 0.2100, Loss avg: 0.0626, lr: 0.000652, BT: 1.19, DT: 0.00
it: [20/74-102/250], rank: [1/1], Loss: 0.0362, Loss avg: 0.0382, lr: 0.000652, BT: 1.08, DT: 0.00
it: [30/74-102/250], rank: [1/1], Loss: 0.0013, Loss avg: 0.0354, lr: 0.000652, BT: 1.09, DT: 0.00
it: [40/74-102/250], rank: [1/1], Loss: 0.0609, Loss avg: 0.0410, lr: 0.000652, BT: 1.18, DT: 0.00
it: [50/74-102/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0353, lr: 0.000652, BT: 1.10, DT: 0.00
it: [60/74-102/250], rank: [1/1], Loss: 0.0012, Loss avg: 0.0332, lr: 0.000652, BT: 1.13, DT: 0.00
it: [70/74-102/250], rank: [1/1], Loss: 0.0012, Loss avg: 0.0338, lr: 0.000652, BT: 1.11, DT: 0.00
Train [102/250]	rank: [1/1], Loss: 0.0327, Acc: 0.9899, Bal Acc: 0.9856, BT: 1.14, DT: 0.01,  epoch time: 84.42
Test [102/250]	Acc: 0.9781, Bal Acc: 0.9599
it: [10/74-103/250], rank: [1/1], Loss: 0.0021, Loss avg: 0.0541, lr: 0.000646, BT: 1.10, DT: 0.00
it: [20/74-103/250], rank: [1/1], Loss: 0.0056, Loss avg: 0.0393, lr: 0.000646, BT: 1.16, DT: 0.00
it: [30/74-103/250], rank: [1/1], Loss: 0.0029, Loss avg: 0.0308, lr: 0.000646, BT: 1.09, DT: 0.00
it: [40/74-103/250], rank: [1/1], Loss: 0.0490, Loss avg: 0.0371, lr: 0.000646, BT: 1.09, DT: 0.00
it: [50/74-103/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0365, lr: 0.000646, BT: 1.23, DT: 0.01
it: [60/74-103/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0378, lr: 0.000646, BT: 1.10, DT: 0.00
it: [70/74-103/250], rank: [1/1], Loss: 0.0953, Loss avg: 0.0389, lr: 0.000646, BT: 1.05, DT: 0.00
Train [103/250]	rank: [1/1], Loss: 0.0371, Acc: 0.9886, Bal Acc: 0.9825, BT: 1.14, DT: 0.01,  epoch time: 84.48
Test [103/250]	Acc: 0.9812, Bal Acc: 0.9782
it: [10/74-104/250], rank: [1/1], Loss: 0.0775, Loss avg: 0.0252, lr: 0.000640, BT: 1.20, DT: 0.01
it: [20/74-104/250], rank: [1/1], Loss: 0.1396, Loss avg: 0.0271, lr: 0.000640, BT: 1.10, DT: 0.00
it: [30/74-104/250], rank: [1/1], Loss: 0.0028, Loss avg: 0.0204, lr: 0.000640, BT: 1.09, DT: 0.00
it: [40/74-104/250], rank: [1/1], Loss: 0.0085, Loss avg: 0.0209, lr: 0.000640, BT: 1.19, DT: 0.01
it: [50/74-104/250], rank: [1/1], Loss: 0.0041, Loss avg: 0.0190, lr: 0.000640, BT: 1.09, DT: 0.00
it: [60/74-104/250], rank: [1/1], Loss: 0.0158, Loss avg: 0.0244, lr: 0.000640, BT: 1.08, DT: 0.00
it: [70/74-104/250], rank: [1/1], Loss: 0.0063, Loss avg: 0.0255, lr: 0.000640, BT: 1.16, DT: 0.00
Train [104/250]	rank: [1/1], Loss: 0.0243, Acc: 0.9932, Bal Acc: 0.9879, BT: 1.14, DT: 0.01,  epoch time: 84.37
Test [104/250]	Acc: 0.9812, Bal Acc: 0.9699
it: [10/74-105/250], rank: [1/1], Loss: 0.0018, Loss avg: 0.0147, lr: 0.000634, BT: 1.11, DT: 0.00
it: [20/74-105/250], rank: [1/1], Loss: 0.0048, Loss avg: 0.0242, lr: 0.000634, BT: 1.21, DT: 0.00
it: [30/74-105/250], rank: [1/1], Loss: 0.0033, Loss avg: 0.0194, lr: 0.000634, BT: 1.10, DT: 0.00
it: [40/74-105/250], rank: [1/1], Loss: 0.0025, Loss avg: 0.0202, lr: 0.000634, BT: 1.09, DT: 0.00
it: [50/74-105/250], rank: [1/1], Loss: 0.0015, Loss avg: 0.0194, lr: 0.000634, BT: 1.21, DT: 0.01
it: [60/74-105/250], rank: [1/1], Loss: 0.0048, Loss avg: 0.0242, lr: 0.000634, BT: 1.11, DT: 0.00
it: [70/74-105/250], rank: [1/1], Loss: 0.0075, Loss avg: 0.0215, lr: 0.000634, BT: 1.05, DT: 0.00
Train [105/250]	rank: [1/1], Loss: 0.0223, Acc: 0.9937, Bal Acc: 0.9890, BT: 1.14, DT: 0.01,  epoch time: 84.49
Test [105/250]	Acc: 0.9688, Bal Acc: 0.9539
it: [10/74-106/250], rank: [1/1], Loss: 0.0074, Loss avg: 0.0396, lr: 0.000628, BT: 1.25, DT: 0.00
it: [20/74-106/250], rank: [1/1], Loss: 0.0018, Loss avg: 0.0290, lr: 0.000628, BT: 1.10, DT: 0.00
it: [30/74-106/250], rank: [1/1], Loss: 0.0924, Loss avg: 0.0319, lr: 0.000628, BT: 1.10, DT: 0.00
it: [40/74-106/250], rank: [1/1], Loss: 0.0431, Loss avg: 0.0341, lr: 0.000628, BT: 1.18, DT: 0.00
it: [50/74-106/250], rank: [1/1], Loss: 0.0231, Loss avg: 0.0361, lr: 0.000628, BT: 1.09, DT: 0.00
it: [60/74-106/250], rank: [1/1], Loss: 0.0056, Loss avg: 0.0325, lr: 0.000628, BT: 1.12, DT: 0.00
it: [70/74-106/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0307, lr: 0.000628, BT: 1.11, DT: 0.00
Train [106/250]	rank: [1/1], Loss: 0.0293, Acc: 0.9907, Bal Acc: 0.9842, BT: 1.14, DT: 0.01,  epoch time: 84.60
Test [106/250]	Acc: 0.9750, Bal Acc: 0.9504
it: [10/74-107/250], rank: [1/1], Loss: 0.0682, Loss avg: 0.0165, lr: 0.000622, BT: 1.08, DT: 0.00
it: [20/74-107/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0154, lr: 0.000622, BT: 1.21, DT: 0.01
it: [30/74-107/250], rank: [1/1], Loss: 0.0034, Loss avg: 0.0199, lr: 0.000622, BT: 1.08, DT: 0.00
it: [40/74-107/250], rank: [1/1], Loss: 0.0029, Loss avg: 0.0269, lr: 0.000622, BT: 1.08, DT: 0.00
it: [50/74-107/250], rank: [1/1], Loss: 0.0016, Loss avg: 0.0286, lr: 0.000622, BT: 1.22, DT: 0.01
it: [60/74-107/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0260, lr: 0.000622, BT: 1.10, DT: 0.00
it: [70/74-107/250], rank: [1/1], Loss: 0.0197, Loss avg: 0.0246, lr: 0.000622, BT: 1.06, DT: 0.00
Train [107/250]	rank: [1/1], Loss: 0.0242, Acc: 0.9916, Bal Acc: 0.9856, BT: 1.14, DT: 0.01,  epoch time: 84.10
Test [107/250]	Acc: 0.9750, Bal Acc: 0.9487
it: [10/74-108/250], rank: [1/1], Loss: 0.0024, Loss avg: 0.0338, lr: 0.000616, BT: 1.17, DT: 0.01
it: [20/74-108/250], rank: [1/1], Loss: 0.0129, Loss avg: 0.0200, lr: 0.000616, BT: 1.09, DT: 0.00
it: [30/74-108/250], rank: [1/1], Loss: 0.1155, Loss avg: 0.0301, lr: 0.000616, BT: 1.19, DT: 0.00
it: [40/74-108/250], rank: [1/1], Loss: 0.0020, Loss avg: 0.0315, lr: 0.000616, BT: 1.22, DT: 0.00
it: [50/74-108/250], rank: [1/1], Loss: 0.0189, Loss avg: 0.0333, lr: 0.000616, BT: 1.09, DT: 0.00
it: [60/74-108/250], rank: [1/1], Loss: 0.0176, Loss avg: 0.0343, lr: 0.000616, BT: 1.08, DT: 0.00
it: [70/74-108/250], rank: [1/1], Loss: 0.0496, Loss avg: 0.0323, lr: 0.000616, BT: 1.14, DT: 0.00
Train [108/250]	rank: [1/1], Loss: 0.0310, Acc: 0.9894, Bal Acc: 0.9776, BT: 1.14, DT: 0.01,  epoch time: 84.58
Test [108/250]	Acc: 0.9781, Bal Acc: 0.9770
it: [10/74-109/250], rank: [1/1], Loss: 0.0174, Loss avg: 0.0227, lr: 0.000610, BT: 1.26, DT: 0.01
it: [20/74-109/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0218, lr: 0.000610, BT: 1.20, DT: 0.00
it: [30/74-109/250], rank: [1/1], Loss: 0.0095, Loss avg: 0.0206, lr: 0.000610, BT: 1.10, DT: 0.00
it: [40/74-109/250], rank: [1/1], Loss: 0.0033, Loss avg: 0.0198, lr: 0.000610, BT: 1.10, DT: 0.00
it: [50/74-109/250], rank: [1/1], Loss: 0.0233, Loss avg: 0.0241, lr: 0.000610, BT: 1.20, DT: 0.01
it: [60/74-109/250], rank: [1/1], Loss: 0.3860, Loss avg: 0.0309, lr: 0.000610, BT: 1.10, DT: 0.01
it: [70/74-109/250], rank: [1/1], Loss: 0.1462, Loss avg: 0.0292, lr: 0.000610, BT: 1.05, DT: 0.00
Train [109/250]	rank: [1/1], Loss: 0.0285, Acc: 0.9899, Bal Acc: 0.9821, BT: 1.14, DT: 0.01,  epoch time: 84.48
Test [109/250]	Acc: 0.9812, Bal Acc: 0.9794
it: [10/74-110/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0075, lr: 0.000604, BT: 1.09, DT: 0.00
it: [20/74-110/250], rank: [1/1], Loss: 0.0010, Loss avg: 0.0123, lr: 0.000604, BT: 1.09, DT: 0.00
it: [30/74-110/250], rank: [1/1], Loss: 0.0036, Loss avg: 0.0142, lr: 0.000604, BT: 1.16, DT: 0.00
it: [40/74-110/250], rank: [1/1], Loss: 0.0124, Loss avg: 0.0146, lr: 0.000604, BT: 1.08, DT: 0.00
it: [50/74-110/250], rank: [1/1], Loss: 0.0297, Loss avg: 0.0130, lr: 0.000604, BT: 1.09, DT: 0.00
it: [60/74-110/250], rank: [1/1], Loss: 0.1148, Loss avg: 0.0192, lr: 0.000604, BT: 1.19, DT: 0.01
it: [70/74-110/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0180, lr: 0.000604, BT: 1.05, DT: 0.00
Train [110/250]	rank: [1/1], Loss: 0.0182, Acc: 0.9928, Bal Acc: 0.9908, BT: 1.15, DT: 0.01,  epoch time: 84.97
Test [110/250]	Acc: 0.9812, Bal Acc: 0.9712
it: [10/74-111/250], rank: [1/1], Loss: 0.0063, Loss avg: 0.0441, lr: 0.000598, BT: 1.20, DT: 0.00
it: [20/74-111/250], rank: [1/1], Loss: 0.0412, Loss avg: 0.0463, lr: 0.000598, BT: 1.09, DT: 0.00
it: [30/74-111/250], rank: [1/1], Loss: 0.0350, Loss avg: 0.0499, lr: 0.000598, BT: 1.10, DT: 0.00
it: [40/74-111/250], rank: [1/1], Loss: 0.0222, Loss avg: 0.0597, lr: 0.000598, BT: 1.23, DT: 0.01
it: [50/74-111/250], rank: [1/1], Loss: 0.0246, Loss avg: 0.0612, lr: 0.000598, BT: 1.09, DT: 0.00
it: [60/74-111/250], rank: [1/1], Loss: 0.1791, Loss avg: 0.0601, lr: 0.000598, BT: 1.08, DT: 0.00
it: [70/74-111/250], rank: [1/1], Loss: 0.0041, Loss avg: 0.0558, lr: 0.000598, BT: 1.14, DT: 0.00
Train [111/250]	rank: [1/1], Loss: 0.0536, Acc: 0.9840, Bal Acc: 0.9744, BT: 1.14, DT: 0.01,  epoch time: 84.17
Test [111/250]	Acc: 0.9688, Bal Acc: 0.9546
it: [10/74-112/250], rank: [1/1], Loss: 0.0050, Loss avg: 0.0187, lr: 0.000592, BT: 1.10, DT: 0.00
it: [20/74-112/250], rank: [1/1], Loss: 0.0054, Loss avg: 0.0146, lr: 0.000592, BT: 1.22, DT: 0.00
it: [30/74-112/250], rank: [1/1], Loss: 0.0090, Loss avg: 0.0242, lr: 0.000592, BT: 1.09, DT: 0.00
it: [40/74-112/250], rank: [1/1], Loss: 0.0156, Loss avg: 0.0205, lr: 0.000592, BT: 1.09, DT: 0.00
it: [50/74-112/250], rank: [1/1], Loss: 0.0038, Loss avg: 0.0238, lr: 0.000592, BT: 1.17, DT: 0.00
it: [60/74-112/250], rank: [1/1], Loss: 0.0138, Loss avg: 0.0237, lr: 0.000592, BT: 1.08, DT: 0.00
it: [70/74-112/250], rank: [1/1], Loss: 0.0135, Loss avg: 0.0261, lr: 0.000592, BT: 1.07, DT: 0.00
Train [112/250]	rank: [1/1], Loss: 0.0248, Acc: 0.9920, Bal Acc: 0.9891, BT: 1.14, DT: 0.01,  epoch time: 84.37
Test [112/250]	Acc: 0.9750, Bal Acc: 0.9579
it: [10/74-113/250], rank: [1/1], Loss: 0.0324, Loss avg: 0.0370, lr: 0.000586, BT: 1.20, DT: 0.01
it: [20/74-113/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0232, lr: 0.000586, BT: 1.09, DT: 0.00
it: [30/74-113/250], rank: [1/1], Loss: 0.0688, Loss avg: 0.0213, lr: 0.000586, BT: 1.20, DT: 0.00
it: [40/74-113/250], rank: [1/1], Loss: 0.0184, Loss avg: 0.0176, lr: 0.000586, BT: 1.17, DT: 0.01
it: [50/74-113/250], rank: [1/1], Loss: 0.0067, Loss avg: 0.0258, lr: 0.000586, BT: 1.09, DT: 0.00
it: [60/74-113/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0236, lr: 0.000586, BT: 1.09, DT: 0.00
it: [70/74-113/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0248, lr: 0.000586, BT: 1.12, DT: 0.00
Train [113/250]	rank: [1/1], Loss: 0.0243, Acc: 0.9920, Bal Acc: 0.9831, BT: 1.14, DT: 0.01,  epoch time: 84.38
Test [113/250]	Acc: 0.9781, Bal Acc: 0.9683
it: [10/74-114/250], rank: [1/1], Loss: 0.0012, Loss avg: 0.0623, lr: 0.000579, BT: 1.10, DT: 0.00
it: [20/74-114/250], rank: [1/1], Loss: 0.0064, Loss avg: 0.0442, lr: 0.000579, BT: 1.19, DT: 0.01
it: [30/74-114/250], rank: [1/1], Loss: 0.0111, Loss avg: 0.0324, lr: 0.000579, BT: 1.09, DT: 0.00
it: [40/74-114/250], rank: [1/1], Loss: 0.0616, Loss avg: 0.0361, lr: 0.000579, BT: 1.09, DT: 0.00
it: [50/74-114/250], rank: [1/1], Loss: 0.0020, Loss avg: 0.0339, lr: 0.000579, BT: 1.20, DT: 0.00
it: [60/74-114/250], rank: [1/1], Loss: 0.0445, Loss avg: 0.0355, lr: 0.000579, BT: 1.10, DT: 0.00
it: [70/74-114/250], rank: [1/1], Loss: 0.0044, Loss avg: 0.0351, lr: 0.000579, BT: 1.06, DT: 0.00
Train [114/250]	rank: [1/1], Loss: 0.0360, Acc: 0.9890, Bal Acc: 0.9769, BT: 1.14, DT: 0.01,  epoch time: 84.58
Test [114/250]	Acc: 0.9719, Bal Acc: 0.9449
it: [10/74-115/250], rank: [1/1], Loss: 0.0070, Loss avg: 0.0261, lr: 0.000573, BT: 1.11, DT: 0.00
it: [20/74-115/250], rank: [1/1], Loss: 0.0014, Loss avg: 0.0193, lr: 0.000573, BT: 1.08, DT: 0.00
it: [30/74-115/250], rank: [1/1], Loss: 0.0044, Loss avg: 0.0196, lr: 0.000573, BT: 1.24, DT: 0.01
it: [40/74-115/250], rank: [1/1], Loss: 0.0422, Loss avg: 0.0168, lr: 0.000573, BT: 1.11, DT: 0.01
it: [50/74-115/250], rank: [1/1], Loss: 0.0022, Loss avg: 0.0167, lr: 0.000573, BT: 1.09, DT: 0.00
it: [60/74-115/250], rank: [1/1], Loss: 0.0002, Loss avg: 0.0233, lr: 0.000573, BT: 1.22, DT: 0.00
it: [70/74-115/250], rank: [1/1], Loss: 0.0038, Loss avg: 0.0220, lr: 0.000573, BT: 1.04, DT: 0.00
Train [115/250]	rank: [1/1], Loss: 0.0240, Acc: 0.9911, Bal Acc: 0.9799, BT: 1.14, DT: 0.01,  epoch time: 84.73
Test [115/250]	Acc: 0.9781, Bal Acc: 0.9664
it: [10/74-116/250], rank: [1/1], Loss: 0.0025, Loss avg: 0.0206, lr: 0.000567, BT: 1.09, DT: 0.00
it: [20/74-116/250], rank: [1/1], Loss: 0.0015, Loss avg: 0.0147, lr: 0.000567, BT: 1.20, DT: 0.00
it: [30/74-116/250], rank: [1/1], Loss: 0.0729, Loss avg: 0.0186, lr: 0.000567, BT: 1.08, DT: 0.00
it: [40/74-116/250], rank: [1/1], Loss: 0.0006, Loss avg: 0.0190, lr: 0.000567, BT: 1.09, DT: 0.00
it: [50/74-116/250], rank: [1/1], Loss: 0.0007, Loss avg: 0.0161, lr: 0.000567, BT: 1.18, DT: 0.01
it: [60/74-116/250], rank: [1/1], Loss: 0.0016, Loss avg: 0.0151, lr: 0.000567, BT: 1.08, DT: 0.00
it: [70/74-116/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0160, lr: 0.000567, BT: 1.07, DT: 0.00
Train [116/250]	rank: [1/1], Loss: 0.0153, Acc: 0.9958, Bal Acc: 0.9900, BT: 1.14, DT: 0.01,  epoch time: 84.35
Test [116/250]	Acc: 0.9750, Bal Acc: 0.9665
it: [10/74-117/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0381, lr: 0.000561, BT: 1.09, DT: 0.00
it: [20/74-117/250], rank: [1/1], Loss: 0.0037, Loss avg: 0.0408, lr: 0.000561, BT: 1.09, DT: 0.01
it: [30/74-117/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0343, lr: 0.000561, BT: 1.24, DT: 0.01
it: [40/74-117/250], rank: [1/1], Loss: 0.0003, Loss avg: 0.0319, lr: 0.000561, BT: 1.11, DT: 0.00
it: [50/74-117/250], rank: [1/1], Loss: 0.0034, Loss avg: 0.0278, lr: 0.000561, BT: 1.10, DT: 0.00
it: [60/74-117/250], rank: [1/1], Loss: 0.0009, Loss avg: 0.0249, lr: 0.000561, BT: 1.19, DT: 0.00
it: [70/74-117/250], rank: [1/1], Loss: 0.2730, Loss avg: 0.0318, lr: 0.000561, BT: 1.05, DT: 0.00
Train [117/250]	rank: [1/1], Loss: 0.0306, Acc: 0.9899, Bal Acc: 0.9791, BT: 1.14, DT: 0.01,  epoch time: 84.76
Test [117/250]	Acc: 0.9812, Bal Acc: 0.9604
it: [10/74-118/250], rank: [1/1], Loss: 0.0679, Loss avg: 0.0196, lr: 0.000555, BT: 1.24, DT: 0.02
it: [20/74-118/250], rank: [1/1], Loss: 0.0019, Loss avg: 0.0167, lr: 0.000555, BT: 1.21, DT: 0.01
it: [30/74-118/250], rank: [1/1], Loss: 0.0031, Loss avg: 0.0149, lr: 0.000555, BT: 1.09, DT: 0.00
it: [40/74-118/250], rank: [1/1], Loss: 0.0013, Loss avg: 0.0151, lr: 0.000555, BT: 1.08, DT: 0.00
it: [50/74-118/250], rank: [1/1], Loss: 0.1269, Loss avg: 0.0184, lr: 0.000555, BT: 1.20, DT: 0.00
it: [60/74-118/250], rank: [1/1], Loss: 0.0204, Loss avg: 0.0183, lr: 0.000555, BT: 1.10, DT: 0.00
it: [70/74-118/250], rank: [1/1], Loss: 0.0274, Loss avg: 0.0220, lr: 0.000555, BT: 1.05, DT: 0.00
Train [118/250]	rank: [1/1], Loss: 0.0214, Acc: 0.9924, Bal Acc: 0.9842, BT: 1.14, DT: 0.01,  epoch time: 84.68
Test [118/250]	Acc: 0.9750, Bal Acc: 0.9656
it: [10/74-119/250], rank: [1/1], Loss: 0.0025, Loss avg: 0.0269, lr: 0.000548, BT: 1.08, DT: 0.00
it: [20/74-119/250], rank: [1/1], Loss: 0.1048, Loss avg: 0.0320, lr: 0.000548, BT: 1.09, DT: 0.00
it: [30/74-119/250], rank: [1/1], Loss: 0.0358, Loss avg: 0.0260, lr: 0.000548, BT: 1.15, DT: 0.00
it: [40/74-119/250], rank: [1/1], Loss: 0.0044, Loss avg: 0.0229, lr: 0.000548, BT: 1.09, DT: 0.00
it: [50/74-119/250], rank: [1/1], Loss: 0.0026, Loss avg: 0.0309, lr: 0.000548, BT: 1.09, DT: 0.00
it: [60/74-119/250], rank: [1/1], Loss: 0.0013, Loss avg: 0.0310, lr: 0.000548, BT: 1.22, DT: 0.00
it: [70/74-119/250], rank: [1/1], Loss: 0.0017, Loss avg: 0.0276, lr: 0.000548, BT: 1.08, DT: 0.00
Train [119/250]	rank: [1/1], Loss: 0.0277, Acc: 0.9886, Bal Acc: 0.9754, BT: 1.14, DT: 0.01,  epoch time: 84.82
Test [119/250]	Acc: 0.9719, Bal Acc: 0.9641
it: [10/74-120/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0341, lr: 0.000542, BT: 1.18, DT: 0.00
it: [20/74-120/250], rank: [1/1], Loss: 0.0028, Loss avg: 0.0262, lr: 0.000542, BT: 1.11, DT: 0.00
it: [30/74-120/250], rank: [1/1], Loss: 0.0008, Loss avg: 0.0201, lr: 0.000542, BT: 1.09, DT: 0.00
it: [40/74-120/250], rank: [1/1], Loss: 0.0282, Loss avg: 0.0235, lr: 0.000542, BT: 1.22, DT: 0.01
it: [50/74-120/250], rank: [1/1], Loss: 0.0029, Loss avg: 0.0194, lr: 0.000542, BT: 1.10, DT: 0.00
it: [60/74-120/250], rank: [1/1], Loss: 0.1596, Loss avg: 0.0239, lr: 0.000542, BT: 1.09, DT: 0.00
it: [70/74-120/250], rank: [1/1], Loss: 0.0058, Loss avg: 0.0236, lr: 0.000542, BT: 1.15, DT: 0.00
Train [120/250]	rank: [1/1], Loss: 0.0231, Acc: 0.9920, Bal Acc: 0.9900, BT: 1.14, DT: 0.01,  epoch time: 84.72
Test [120/250]	Acc: 0.9781, Bal Acc: 0.9682
it: [10/74-121/250], rank: [1/1], Loss: 0.0027, Loss avg: 0.0056, lr: 0.000536, BT: 1.09, DT: 0.00
it: [20/74-121/250], rank: [1/1], Loss: 0.0005, Loss avg: 0.0102, lr: 0.000536, BT: 1.23, DT: 0.00
it: [30/74-121/250], rank: [1/1], Loss: 0.0019, Loss avg: 0.0102, lr: 0.000536, BT: 1.09, DT: 0.00
it: [40/74-121/250], rank: [1/1], Loss: 0.0012, Loss avg: 0.0108, lr: 0.000536, BT: 1.15, DT: 0.00
it: [50/74-121/250], rank: [1/1], Loss: 0.0266, Loss avg: 0.0098, lr: 0.000536, BT: 1.26, DT: 0.01
it: [60/74-121/250], rank: [1/1], Loss: 0.0004, Loss avg: 0.0110, lr: 0.000536, BT: 1.09, DT: 0.00
it: [70/74-121/250], rank: [1/1], Loss: 0.0011, Loss avg: 0.0108, lr: 0.000536, BT: 1.05, DT: 0.00
Train [121/250]	rank: [1/1], Loss: 0.0111, Acc: 0.9962, Bal Acc: 0.9919, BT: 1.15, DT: 0.01,  epoch time: 85.00
Test [121/250]	Acc: 0.9812, Bal Acc: 0.9793
